#!/usr/bin/env python
# coding: utf-8

# In[2]:


#17se02ce018
import pandas as pd

cols = ['sent','class']
rows = []

rows = [['This is my Book','stmt'],
        ['They are novels','stmt'],
        ['Have you read this book','question'],
        ['Who is the author','question'],
        ['What are the characters','question'],
        ['This is how I bought the book','stmt'],
        ['I like fictions','stmt'],
        ['What is your favorite book','question']]

train_data = pd.DataFrame(rows, columns=cols)
train_data


# In[3]:


from sklearn.feature_extraction.text import CountVectorizer

stmt_docs = [row['sent'] for index,row in train_data.iterrows() if row['class'] == 'stmt']

vec_s = CountVectorizer()
X_s = vec_s.fit_transform(stmt_docs)
tdm_s = pd.DataFrame(X_s.toarray(), columns = vec_s.get_feature_names())

tdm_s


# In[4]:


q_docs = [row['sent'] for index,row in train_data.iterrows() if row['class'] == 'question']

vec_q = CountVectorizer()
X_q = vec_q.fit_transform(q_docs)
tdm_q = pd.DataFrame(X_q.toarray(), columns = vec_q.get_feature_names())

tdm_q


# In[7]:


word_list_s = vec_s.get_feature_names();
count_list_s = X_s.toarray().sum(axis=0)
freq_s = dict(zip(word_list_s,count_list_s))


# In[8]:


freq_s


# In[9]:


word_list_q = vec_q.get_feature_names();
count_list_q = X_q.toarray().sum(axis=0)
freq_q = dict(zip(word_list_q,count_list_q))


# In[10]:


freq_q


# In[13]:


prob_s = []
for word,count in zip(word_list_s,count_list_s):
    prob_s.append(count/len(word_list_s))
dict(zip(word_list_s,prob_s))


# In[14]:


prob_q = []
for count in count_list_q:
    prob_q.append(count/len(word_list_q))
dict(zip(word_list_q,prob_q))


# In[16]:


from sklearn.feature_extraction.text import CountVectorizer

docs = [row['sent'] for index,row in train_data.iterrows()]

vec = CountVectorizer()
X = vec.fit_transform(docs)

total_features = len(vec.get_feature_names())


# In[17]:


total_features


# In[18]:


total_cnts_features_s = count_list_s.sum(axis=0)
total_cnts_features_q = count_list_q.sum(axis=0)


# In[19]:


from nltk.tokenize import word_tokenize

new_sentence = 'what is the price of the book'
new_word_list = word_tokenize(new_sentence)


# In[20]:


prob_s_with_ls = []
for word in new_word_list:
    if word in freq_s.keys():
        count = freq_s[word]
    else:
        count = 0
    prob_s_with_ls.append((count + 1)/(total_cnts_features_s + total_features))
dict(zip(new_word_list,prob_s_with_ls))


# In[21]:


prob_q_with_ls = []
for word in new_word_list:
    if word in freq_q.keys():
        count = freq_q[word]
    else:
        count = 0
    prob_q_with_ls.append((count + 1)/(total_cnts_features_q + total_features))
dict(zip(new_word_list,prob_q_with_ls))


# In[ ]:




